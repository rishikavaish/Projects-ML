{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "building_the_classifier_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOtNE4_26SMH"
      },
      "source": [
        "# **BUILDING THE CLASSIFIER MODEL BY APPLYING NLP**\n",
        "## Steps(from scraping data to building model)\n",
        "*   Scrape reviews from a google playstore apps\n",
        "*   Text Preprocessing\n",
        "*   Text clustering\n",
        "*   Fine tune a pretrained XLNet model\n",
        "*   Generate Predictions\n",
        "\n",
        "# Scrape Google Playstore reviews using google-play-scraper and MongoDB\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsYXXode6QRl"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# for scraping app info and reviews from Google Play\n",
        "from google_play_scraper import app, Sort, reviews\n",
        "\n",
        "# for pretty printing data structures\n",
        "from pprint import pprint\n",
        "\n",
        "# for storing in MongoDB\n",
        "import pymongo\n",
        "from pymongo import MongoClient\n",
        "\n",
        "# for keeping track of timing\n",
        "import datetime as dt\n",
        "from tzlocal import get_localzone\n",
        "\n",
        "# for building in wait times\n",
        "import random\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvOgap-J7ZZE"
      },
      "source": [
        "# Set up Mongo client\n",
        "client = MongoClient(host='localhost', port=27017)\n",
        "\n",
        "# Database for project\n",
        "app_proj_db = client['app_proj_db']\n",
        "\n",
        "# Set up new collection within project db for app reviews\n",
        "review_collection = app_proj_db['review_collection']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNVvBhmq7hLd"
      },
      "source": [
        "# choosing some random app names along with their app ids\n",
        "app_names = ['SBI',\n",
        "'UNION',\n",
        "'CBOI',\n",
        "'BOI',\n",
        "'CORP',\n",
        "'IOB',\n",
        "'LVB',\n",
        "'KVB']\n",
        "app_ids =  [\n",
        "  'com.freedomrewardz',\n",
        "'com.unionrewardz',\n",
        "'com.centrewardz',\n",
        "'com.boistarrewardz',\n",
        "'com.corprewardz',\n",
        "'com.iobrewardz',\n",
        "'com.lvbrewardz',\n",
        "'com.kvbrewardz'\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvDQg0Em7zSE"
      },
      "source": [
        "#Looping through app_ids and app_names to get reviews\n",
        "for app_name, app_id in zip(app_names, app_ids):\n",
        "    \n",
        "    # Get the starting time\n",
        "    start = dt.datetime.now(tz=get_localzone())\n",
        "    fmt= \"%m/%d/%y - %T %p\"    \n",
        "    print('-------------------------------------------------------------------------')    \n",
        "    print(f'{app_name} started at {start.strftime(fmt)}')\n",
        "    print()\n",
        "    \n",
        "    # Empty list for storing reviews\n",
        "    app_reviews = []\n",
        "    \n",
        "    # Number of reviews to scrape per batch\n",
        "    count = 200\n",
        "    \n",
        "    # To keep track of how many batches have been completed\n",
        "    batch_num = 0\n",
        "    \n",
        "    \n",
        "    # Retrieve reviews (and continuation_token) with reviews function\n",
        "    rvws, token = reviews(\n",
        "        app_id,           # found in app's url\n",
        "        lang='en',        # defaults to 'en'\n",
        "        country='us',     # defaults to 'us'\n",
        "        sort=Sort.NEWEST, # start with most recent\n",
        "        count=count       # batch size\n",
        "    )\n",
        "    \n",
        "    \n",
        "    # For each review get an app name and app id\n",
        "    for r in rvws:\n",
        "        r['app_name'] = app_name \n",
        "        r['app_id'] = app_id     \n",
        "     \n",
        "    \n",
        "    # Add the list of review dicts to overall list\n",
        "    app_reviews.extend(rvws)\n",
        "    \n",
        "    # Increase batch count by one\n",
        "    batch_num +=1 \n",
        "    print(f'Batch {batch_num} completed.')\n",
        "    \n",
        "    # Wait 1 to 5 seconds to start next batch\n",
        "    time.sleep(random.randint(1,5))\n",
        "    \n",
        "    \n",
        "    \n",
        "    # Append review IDs\n",
        "    pre_review_ids = []\n",
        "    for rvw in app_reviews:\n",
        "        pre_review_ids.append(rvw['reviewId'])\n",
        "    \n",
        "    \n",
        "    # Loop through at most max number of batches\n",
        "    for batch in range(4999):\n",
        "        rvws, token = reviews( \n",
        "            app_id,\n",
        "            lang='en',\n",
        "            country='us',\n",
        "            sort=Sort.NEWEST,\n",
        "            count=count,\n",
        "            # using token obtained from previous batch\n",
        "            continuation_token=token\n",
        "        )\n",
        "        \n",
        "        # Append unique review IDs from current batch to new list\n",
        "        new_review_ids = []\n",
        "        for r in rvws:\n",
        "            new_review_ids.append(r['reviewId'])\n",
        "            \n",
        "            # And add keys for name and id to the review dict\n",
        "            r['app_name'] = app_name \n",
        "            r['app_id'] = app_id     \n",
        "     \n",
        "        # Add the list of review dicts to app_reviews list\n",
        "        app_reviews.extend(rvws)\n",
        "        \n",
        "        # Increase batch count by one\n",
        "        batch_num +=1\n",
        "        \n",
        "        # Break loop and stop scraping for current app if most recent batch\n",
        "        # did not add any unique reviews\n",
        "        all_review_ids = pre_review_ids + new_review_ids\n",
        "        if len(set(pre_review_ids)) == len(set(all_review_ids)):\n",
        "            print(f'No reviews left to scrape. Completed {batch_num} batches.\\n')\n",
        "            break\n",
        "        \n",
        "        # all_review_ids becomes pre_review_ids to check against \n",
        "        # for next batch\n",
        "        pre_review_ids = all_review_ids\n",
        "        \n",
        "        \n",
        "        # At every 100th batch\n",
        "        if batch_num%100==0:\n",
        "            \n",
        "            # print update on number of batches\n",
        "            print(f'Batch {batch_num} completed.')\n",
        "            \n",
        "            # insert reviews into collection\n",
        "            review_collection.insert_many(app_reviews)\n",
        "            \n",
        "            # print update about num reviews inserted\n",
        "            store_time = dt.datetime.now(tz=get_localzone())\n",
        "            print(f\"\"\"\n",
        "            Successfully inserted {len(app_reviews)} {app_name} \n",
        "            reviews into collection at {store_time.strftime(fmt)}.\\n\n",
        "            \"\"\")\n",
        "            \n",
        "            # empty our list for next round of 100 batches\n",
        "            app_reviews = []\n",
        "        \n",
        "        # Wait 1 to 5 seconds to start next batch\n",
        "        time.sleep(random.randint(1,5))\n",
        "      \n",
        "    \n",
        "    # Print update when max number of batches has been reached\n",
        "    # OR when last batch didn't add any unique reviews\n",
        "    print(f'Done scraping {app_name}.')\n",
        "    print(f'Scraped a total of {len(set(pre_review_ids))} unique reviews.\\n')\n",
        "    \n",
        "    \n",
        "    # Insert remaining reviews into collection\n",
        "    review_collection.insert_many(app_reviews)\n",
        "    \n",
        "    # Get end time\n",
        "    end = dt.datetime.now(tz=get_localzone())\n",
        "    \n",
        "    # Print ending output for app\n",
        "    print(f\"\"\"\n",
        "    Successfully inserted all {app_name} reviews into collection\n",
        "    at {end.strftime(fmt)}.\\n\n",
        "    \"\"\")\n",
        "    print(f'Time taken to scrape reviews for {app_name}: {end-start}')\n",
        "    print('-----------------------------------------------------------------------')\n",
        "    print('\\n')\n",
        "    \n",
        "    # Wait 1 to 5 seconds to start scraping next app\n",
        "    time.sleep(random.randint(1,5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGU35YCu757t"
      },
      "source": [
        "# converting the results into dataframe\n",
        "app_reviews_df = pd.DataFrame(list(review_collection.find({})))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27z2COMJ8TNs"
      },
      "source": [
        "#splitting the 'at' column into date and time separately\n",
        "\n",
        "# make string version of original column, call it 'col'\n",
        "app_reviews_df['col'] = app_reviews_df['at'].astype(str)\n",
        "\n",
        "# make the new columns using string indexing\n",
        "app_reviews_df['date'] = app_reviews_df['col'].str[0:11]\n",
        "app_reviews_df['time'] = app_reviews_df['col'].str[11:20]\n",
        "\n",
        "# get rid of the extra variable\n",
        "app_reviews_df.drop('col', axis=1, inplace=True)\n",
        "app_reviews_df.drop('at', axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAkxRiOq8Xd9"
      },
      "source": [
        "app_reviews_df['date'] = pd.to_datetime(app_reviews_df['date'])\n",
        "  \n",
        "start_date = '01-01-2019'\n",
        "end_date = '03-31-2021'\n",
        "\n",
        "mask = (app_reviews_df['date'] > start_date) & (app_reviews_df['date'] <= end_date)\n",
        "app_reviews_df = app_reviews_df.loc[mask]\n",
        "\n",
        "del app_reviews_df['repliedAt']\n",
        "\n",
        "app_reviews_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdYBgMK48cHW"
      },
      "source": [
        "# you might get some duplicates. To remove duplicates:\n",
        "app_reviews_df = app_reviews_df.drop_duplicates(subset=['reviewId'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIRhntO28sBV"
      },
      "source": [
        "#convert the final dataframe into csv\n",
        "app_reviews_df.to_csv('sbi_reviews_final.csv', index=None, header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9Vl82XM-I1D"
      },
      "source": [
        "# Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAGIOi0e9grl"
      },
      "source": [
        "#load the data\n",
        "sample=pd.read_csv(\"sbi_reviews_final.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0GjZMsy-Oia"
      },
      "source": [
        "# find sentences containing HTML tags\n",
        "import re\n",
        "i=0;\n",
        "for sent in sample['content'].values:\n",
        "    if (len(re.findall('<.*?>', sent))):\n",
        "        print(i)\n",
        "        print(sent)\n",
        "        break;\n",
        "    i += 1;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnyId2lq-e_8"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "#initialising the snowball stemmer which is developed in recent years\n",
        "sno = nltk.stem.SnowballStemmer('english') \n",
        "stop=set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "#function to clean the word of any html-tags\n",
        "def cleanhtml(sentence): \n",
        "    cleanr = re.compile('<.*?>')\n",
        "    cleantext = re.sub(cleanr, ' ', sentence)\n",
        "    return cleantext\n",
        "#function to clean the word of any punctuation or special characters\n",
        "def cleanpunc(sentence): \n",
        "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
        "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
        "    return  cleaned"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYnNZC_t-yir"
      },
      "source": [
        "i=0\n",
        "str1=' '\n",
        "final_string=[]\n",
        "all_positive_words=[] # store words from +ve reviews here\n",
        "all_negative_words=[] # store words from -ve reviews here.\n",
        "s=''\n",
        "for sent in sample['content'].values:\n",
        "    filtered_sentence=[]\n",
        "    #print(sent);\n",
        "    sent=cleanhtml(sent) # remove HTMl tags\n",
        "    for w in sent.split():\n",
        "        for cleaned_words in cleanpunc(w).split():\n",
        "            if((cleaned_words.isalpha()) & (len(cleaned_words)>2)):    \n",
        "                if(cleaned_words.lower() not in stop):\n",
        "                    s=(sno.stem(cleaned_words.lower())).encode('utf8')\n",
        "                    filtered_sentence.append(s)\n",
        "                    if (sample['Sentiment'].values)[i] == 'positive': \n",
        "                        all_positive_words.append(s) #list of all words used to describe positive reviews\n",
        "                    if(sample['Sentiment'].values)[i] == 'negative':\n",
        "                        all_negative_words.append(s) #list of all words used to describe negative reviews reviews\n",
        "                else:\n",
        "                    continue\n",
        "            else:\n",
        "                continue \n",
        "    #print(filtered_sentence)\n",
        "    str1 = b\" \".join(filtered_sentence) #final string of cleaned words\n",
        "    #print(\"***********************************************************************\")\n",
        "    \n",
        "    final_string.append(str1)\n",
        "    i+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rI8eRCMi_BJo"
      },
      "source": [
        "#adding a column of CleanedText which displays the data after pre-processing of the review\n",
        "sample['CleanedText']=final_string  \n",
        "sample['CleanedText']=sample['CleanedText'].str.decode(\"utf-8\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tupVPhDF_W-c"
      },
      "source": [
        "# Text Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFzKraHB_3W9"
      },
      "source": [
        "Text clustering is done using tf-idf and k-means clustering and then the final clusteres are formed using n-grams method. In this n-grams technique, you have to make n-grams for each cluster and pick only those words which belong to that particular category, basically, the words which are more frequent in that cluster.\n",
        "\n",
        "Any other method can be used for text clustering depending on different datasets and any desired number of categories can be formed for that dataset.\n",
        "\n",
        "Here, seven categories were made after clustering and then stored into a csv called 'clustered_data.csv' which is provided in the repository for direct use. It shows the format in which the clustered data was made by doing some data wrangling.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0p6amibrBjZf"
      },
      "source": [
        "# Building the Classifier Model\n",
        "A pretrained **XLNet model** has been used for classification and then this pretrained XLNet model was fine tuned by training it on the clustered data. And, after preprocessing the data and training the model on this data, a function was formed for getting predictions for a new data along with the probabilities of each label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwTHAUqXk7_B"
      },
      "source": [
        "# import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import math\n",
        "import torch\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import AdamW, XLNetTokenizer, XLNetModel, XLNetLMHeadModel, XLNetConfig\n",
        "from transformers import XLNetTokenizerFast\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm, trange\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZbLvzAKlmsP"
      },
      "source": [
        "## Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2Xf8DAOl0XH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "df9aa02b-6ce5-495a-bafb-00d8ae6ef349"
      },
      "source": [
        "df = pd.read_csv('clustered_data.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewId</th>\n",
              "      <th>content</th>\n",
              "      <th>Problem in recharge</th>\n",
              "      <th>Problem in reward/redeem points</th>\n",
              "      <th>Problem in registration/login/username/password</th>\n",
              "      <th>Problem with customer care service</th>\n",
              "      <th>Other complaints</th>\n",
              "      <th>Bad comments</th>\n",
              "      <th>Appreciation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gp:AOqpTOGke5oHGTtgbNCNSurTU8c4h9j0aJgkGSKqvlO...</td>\n",
              "      <td>for mobile recharge, this is very excellent app.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gp:AOqpTOFGUaCTHYLrzFzaAusdm-wc1Rm9cUyHjgzzuwY...</td>\n",
              "      <td>awesome app for recharge and collect point any...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gp:AOqpTOFldCmXCDu4Ji5GGBZheX1k057zvjenXeydSCg...</td>\n",
              "      <td>smooth and trouble free recharge.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gp:AOqpTOHZne9EjZEQd8AWRd4rKr-Jmzk_nCQPb2wOqJp...</td>\n",
              "      <td>very nice app for revard and to use it to rech...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gp:AOqpTOHlQooz_z4BGtqsPAlx99zdOvJOt6Nj3OBCkEA...</td>\n",
              "      <td>good for mobile recharge</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            reviewId  ... Appreciation\n",
              "0  gp:AOqpTOGke5oHGTtgbNCNSurTU8c4h9j0aJgkGSKqvlO...  ...            1\n",
              "1  gp:AOqpTOFGUaCTHYLrzFzaAusdm-wc1Rm9cUyHjgzzuwY...  ...            1\n",
              "2  gp:AOqpTOFldCmXCDu4Ji5GGBZheX1k057zvjenXeydSCg...  ...            1\n",
              "3  gp:AOqpTOHZne9EjZEQd8AWRd4rKr-Jmzk_nCQPb2wOqJp...  ...            1\n",
              "4  gp:AOqpTOHlQooz_z4BGtqsPAlx99zdOvJOt6Nj3OBCkEA...  ...            1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTwkEX4JCziK",
        "outputId": "f8c0c235-d28b-4081-96d7-b8d331b5c07c"
      },
      "source": [
        "# Split the data:\n",
        "train, test = train_test_split(df, test_size=0.05)\n",
        "train.shape, test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((14747, 9), (777, 9))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1CjLi8LdP1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "eb0f5ec2-0f01-447a-93f7-45db39038e09"
      },
      "source": [
        "train = train.set_index('reviewId')\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>Problem in recharge</th>\n",
              "      <th>Problem in reward/redeem points</th>\n",
              "      <th>Problem in registration/login/username/password</th>\n",
              "      <th>Problem with customer care service</th>\n",
              "      <th>Other complaints</th>\n",
              "      <th>Bad comments</th>\n",
              "      <th>Appreciation</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reviewId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>gp:AOqpTOH8jCaAwdk9-qE_MmxJ97tAXE30k37mUBiYpR7cmyyDyw0HMuUrD-URMKP3q-9kr3LXDshnFqO-hgDFRyA</th>\n",
              "      <td>waste of using this app , could not activate m...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gp:AOqpTOEjgWcte_Y0Afg-qIeTJ-rUJnc_r__g3_6OjfGBqcGCT-1xrVtGzQV7YnxxsY8gel4ZJvGAKR3buKSrCU0</th>\n",
              "      <td>good</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gp:AOqpTOGniFIBHNn4xutfeb3zYgfS1_nomysuhv6iXaa0LLb_qq9bGJdWUQrn4J1xlSJY050ED2c9GirVxiOSROE</th>\n",
              "      <td>not good</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gp:AOqpTOGQoTMiP_dpiv7tnjkvRfkqQDeR5_Ffcz7vqNMlz59LaZ0AJjltwYf8TfFnBvW2iAutxdozt7F8u3Va7UU</th>\n",
              "      <td>mobile recharge is not done while reward point...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gp:AOqpTOHJsvpGEYcklDS7kYRCSjFeO7dWTCRLSvFHxOVsUUgcvzanxIvIpdRJGEsKw8axauDb_2y2s8BpnhiziR0</th>\n",
              "      <td>worst experience, terrible performance by the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                              content  ...  Appreciation\n",
              "reviewId                                                                                               ...              \n",
              "gp:AOqpTOH8jCaAwdk9-qE_MmxJ97tAXE30k37mUBiYpR7c...  waste of using this app , could not activate m...  ...             0\n",
              "gp:AOqpTOEjgWcte_Y0Afg-qIeTJ-rUJnc_r__g3_6OjfGB...                                               good  ...             1\n",
              "gp:AOqpTOGniFIBHNn4xutfeb3zYgfS1_nomysuhv6iXaa0...                                           not good  ...             0\n",
              "gp:AOqpTOGQoTMiP_dpiv7tnjkvRfkqQDeR5_Ffcz7vqNMl...  mobile recharge is not done while reward point...  ...             0\n",
              "gp:AOqpTOHJsvpGEYcklDS7kYRCSjFeO7dWTCRLSvFHxOVs...  worst experience, terrible performance by the ...  ...             0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWX6qJg-dRcR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "110ae795-f093-4896-b6e0-f426c5fb7b18"
      },
      "source": [
        "test = test[['reviewId','content']]\n",
        "test = test.set_index('reviewId')\n",
        "test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reviewId</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>gp:AOqpTOGTADrOKHFXYgD5jwLGK1Ult0gcnjTCj3fqrKk4AEjJiPK90jg-o56Vf6X_Mtfbcibv6dEw3b5IqXR5mz0</th>\n",
              "      <td>good boy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gp:AOqpTOHG20z1AXXSPa5cRQQXNS3Mri57rOo9JNu0MZBZxnx8wgNl6oecPTvUEDZBJ1ix3ovWeYvsMgNUlNfdMJc</th>\n",
              "      <td>very nice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gp:AOqpTOEjMUAO5sa_j77QG0hp75avoD2FwOjevIlNWcXhLDyl6RZHpKyuO15V_kambTEUfczaPvSeQKTdYwfwVNI</th>\n",
              "      <td>bad app</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gp:AOqpTOHxMcsJGLebsXniRuZk71y546Y-tCV0ME-gaZby9COr_vTk1c6Axe-T2jeejxwKsEaAHbbs7onwe3EQLPU</th>\n",
              "      <td>worst app</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gp:AOqpTOFGo_lltI1X7gImeKrUe7tnKJT0Nst6IIujSWrg9exW6eF5BA-b50g5XRXnVJBlbuyTSNhoOyonPZ-4Yzo</th>\n",
              "      <td>i have successfully registered but when i try ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                              content\n",
              "reviewId                                                                                             \n",
              "gp:AOqpTOGTADrOKHFXYgD5jwLGK1Ult0gcnjTCj3fqrKk4...                                           good boy\n",
              "gp:AOqpTOHG20z1AXXSPa5cRQQXNS3Mri57rOo9JNu0MZBZ...                                          very nice\n",
              "gp:AOqpTOEjMUAO5sa_j77QG0hp75avoD2FwOjevIlNWcXh...                                            bad app\n",
              "gp:AOqpTOHxMcsJGLebsXniRuZk71y546Y-tCV0ME-gaZby...                                          worst app\n",
              "gp:AOqpTOFGo_lltI1X7gImeKrUe7tnKJT0Nst6IIujSWrg...  i have successfully registered but when i try ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zz9OzE2TmSN1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5d03d78-2d1b-4e2d-fe04-d8aeaec38108"
      },
      "source": [
        "train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14747, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW3dJFOTMkq1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c63916d5-7e80-4f7c-aa97-ed7f11928677"
      },
      "source": [
        "test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(777, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MN8bQOt2mVc5"
      },
      "source": [
        "# Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTOd-qKQMyFO"
      },
      "source": [
        "# tokenize data\n",
        "tokenizer = XLNetTokenizerFast.from_pretrained('xlnet-base-cased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3Xq-qP54SiF"
      },
      "source": [
        "train_text_list = train[\"content\"].values\n",
        "test_text_list = test[\"content\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocveMTIfM5cP"
      },
      "source": [
        "def tokenize_inputs(text_list, tokenizer, num_embeddings=512):\n",
        "    \"\"\"\n",
        "    Tokenizes the input text input into ids. Appends the appropriate special\n",
        "    characters to the end of the text to denote end of sentence. Truncate or pad\n",
        "    the appropriate sequence length.\n",
        "    \"\"\"\n",
        "    # tokenize the text, then truncate sequence to the desired length minus 2 for\n",
        "    # the 2 special characters\n",
        "    tokenized_texts = list(map(lambda t: tokenizer.tokenize(t)[:num_embeddings-2], text_list))\n",
        "    # convert tokenized text into numeric ids for the appropriate LM\n",
        "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "    # append special token \"<s>\" and </s> to end of sentence\n",
        "    input_ids = [tokenizer.build_inputs_with_special_tokens(x) for x in input_ids]\n",
        "    # pad sequences\n",
        "    input_ids = pad_sequences(input_ids, maxlen=num_embeddings, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "    return input_ids\n",
        "\n",
        "def create_attn_masks(input_ids):\n",
        "    \"\"\"\n",
        "    Create attention masks to tell model whether attention should be applied to\n",
        "    the input id tokens. Do not want to perform attention on padding tokens.\n",
        "    \"\"\"\n",
        "    # Create attention masks\n",
        "    attention_masks = []\n",
        "\n",
        "    # Create a mask of 1s for each token followed by 0s for padding\n",
        "    for seq in input_ids:\n",
        "        seq_mask = [float(i>0) for i in seq]\n",
        "        attention_masks.append(seq_mask)\n",
        "    return attention_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2ZVLj_OM8sV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d13eda6-19e4-49dd-8178-2a7adfd70481"
      },
      "source": [
        "# create input id tokens\n",
        "train_input_ids = tokenize_inputs(train_text_list, tokenizer, num_embeddings=250)\n",
        "train_input_ids"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3419,   20,  381, ...,    0,    0,    0],\n",
              "       [ 195,    4,    3, ...,    0,    0,    0],\n",
              "       [  50,  195,    4, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [  36,   26,   23, ...,    0,    0,    0],\n",
              "       [  36,  172, 2101, ...,    0,    0,    0],\n",
              "       [  50,  195,    4, ...,    0,    0,    0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrzAuQ_6M-ER",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "106d0190-74d7-4c32-ef3f-b712cc0d76c3"
      },
      "source": [
        "# create input id tokens\n",
        "test_input_ids = tokenize_inputs(test_text_list, tokenizer, num_embeddings=250)\n",
        "test_input_ids"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 195, 2001,    4, ...,    0,    0,    0],\n",
              "       [ 172, 2101,    4, ...,    0,    0,    0],\n",
              "       [ 948, 5523,    4, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [  17,  150,   17, ...,    0,    0,    0],\n",
              "       [ 312, 5523,   21, ...,    0,    0,    0],\n",
              "       [ 195,    4,    3, ...,    0,    0,    0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgGLmaKKM_xB"
      },
      "source": [
        "# create attention masks\n",
        "train_attention_masks = create_attn_masks(train_input_ids)\n",
        "# train_attention_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdX4QlnZTeaN"
      },
      "source": [
        "# create attention masks\n",
        "test_attention_masks = create_attn_masks(test_input_ids)\n",
        "# test_attention_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQPuY4mONCSu"
      },
      "source": [
        "# add input ids and attention masks to the dataframe\n",
        "train[\"features\"] = train_input_ids.tolist()\n",
        "train[\"masks\"] = train_attention_masks\n",
        "\n",
        "test[\"features\"] = test_input_ids.tolist()\n",
        "test[\"masks\"] = test_attention_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjzFlRljNEkB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6031c9c6-a29d-412b-9568-14572637eb51"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>Problem in recharge</th>\n",
              "      <th>Problem in reward/redeem points</th>\n",
              "      <th>Problem in registration/login/username/password</th>\n",
              "      <th>Problem with customer care service</th>\n",
              "      <th>Other complaints</th>\n",
              "      <th>Bad comments</th>\n",
              "      <th>Appreciation</th>\n",
              "      <th>features</th>\n",
              "      <th>masks</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reviewId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>gp:AOqpTOH8jCaAwdk9-qE_MmxJ97tAXE30k37mUBiYpR7cmyyDyw0HMuUrD-URMKP3q-9kr3LXDshnFqO-hgDFRyA</th>\n",
              "      <td>waste of using this app , could not activate m...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[3419, 20, 381, 52, 5523, 17, 19, 121, 50, 177...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gp:AOqpTOEjgWcte_Y0Afg-qIeTJ-rUJnc_r__g3_6OjfGBqcGCT-1xrVtGzQV7YnxxsY8gel4ZJvGAKR3buKSrCU0</th>\n",
              "      <td>good</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[195, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gp:AOqpTOGniFIBHNn4xutfeb3zYgfS1_nomysuhv6iXaa0LLb_qq9bGJdWUQrn4J1xlSJY050ED2c9GirVxiOSROE</th>\n",
              "      <td>not good</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[50, 195, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gp:AOqpTOGQoTMiP_dpiv7tnjkvRfkqQDeR5_Ffcz7vqNMlz59LaZ0AJjltwYf8TfFnBvW2iAutxdozt7F8u3Va7UU</th>\n",
              "      <td>mobile recharge is not done while reward point...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[2487, 23140, 27, 50, 588, 171, 8614, 424, 186...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gp:AOqpTOHJsvpGEYcklDS7kYRCSjFeO7dWTCRLSvFHxOVsUUgcvzanxIvIpdRJGEsKw8axauDb_2y2s8BpnhiziR0</th>\n",
              "      <td>worst experience, terrible performance by the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[2598, 656, 19, 6518, 922, 37, 18, 5523, 9, 4,...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                              content  ...                                              masks\n",
              "reviewId                                                                                               ...                                                   \n",
              "gp:AOqpTOH8jCaAwdk9-qE_MmxJ97tAXE30k37mUBiYpR7c...  waste of using this app , could not activate m...  ...  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
              "gp:AOqpTOEjgWcte_Y0Afg-qIeTJ-rUJnc_r__g3_6OjfGB...                                               good  ...  [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "gp:AOqpTOGniFIBHNn4xutfeb3zYgfS1_nomysuhv6iXaa0...                                           not good  ...  [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "gp:AOqpTOGQoTMiP_dpiv7tnjkvRfkqQDeR5_Ffcz7vqNMl...  mobile recharge is not done while reward point...  ...  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
              "gp:AOqpTOHJsvpGEYcklDS7kYRCSjFeO7dWTCRLSvFHxOVs...  worst experience, terrible performance by the ...  ...  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDcrK191NG_K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "52932156-8ad7-473c-82a2-cd23dde4b668"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>features</th>\n",
              "      <th>masks</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reviewId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>gp:AOqpTOGTADrOKHFXYgD5jwLGK1Ult0gcnjTCj3fqrKk4AEjJiPK90jg-o56Vf6X_Mtfbcibv6dEw3b5IqXR5mz0</th>\n",
              "      <td>good boy</td>\n",
              "      <td>[195, 2001, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gp:AOqpTOHG20z1AXXSPa5cRQQXNS3Mri57rOo9JNu0MZBZxnx8wgNl6oecPTvUEDZBJ1ix3ovWeYvsMgNUlNfdMJc</th>\n",
              "      <td>very nice</td>\n",
              "      <td>[172, 2101, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gp:AOqpTOEjMUAO5sa_j77QG0hp75avoD2FwOjevIlNWcXhLDyl6RZHpKyuO15V_kambTEUfczaPvSeQKTdYwfwVNI</th>\n",
              "      <td>bad app</td>\n",
              "      <td>[948, 5523, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gp:AOqpTOHxMcsJGLebsXniRuZk71y546Y-tCV0ME-gaZby9COr_vTk1c6Axe-T2jeejxwKsEaAHbbs7onwe3EQLPU</th>\n",
              "      <td>worst app</td>\n",
              "      <td>[2598, 5523, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gp:AOqpTOFGo_lltI1X7gImeKrUe7tnKJT0Nst6IIujSWrg9exW6eF5BA-b50g5XRXnVJBlbuyTSNhoOyonPZ-4Yzo</th>\n",
              "      <td>i have successfully registered but when i try ...</td>\n",
              "      <td>[17, 150, 47, 3918, 2815, 57, 90, 17, 150, 714...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                              content  ...                                              masks\n",
              "reviewId                                                                                               ...                                                   \n",
              "gp:AOqpTOGTADrOKHFXYgD5jwLGK1Ult0gcnjTCj3fqrKk4...                                           good boy  ...  [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "gp:AOqpTOHG20z1AXXSPa5cRQQXNS3Mri57rOo9JNu0MZBZ...                                          very nice  ...  [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "gp:AOqpTOEjMUAO5sa_j77QG0hp75avoD2FwOjevIlNWcXh...                                            bad app  ...  [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "gp:AOqpTOHxMcsJGLebsXniRuZk71y546Y-tCV0ME-gaZby...                                          worst app  ...  [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "gp:AOqpTOFGo_lltI1X7gImeKrUe7tnKJT0Nst6IIujSWrg...  i have successfully registered but when i try ...  ...  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRpKDj-WN2tN"
      },
      "source": [
        "# Train, Valid Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1SXXP4GN1m_"
      },
      "source": [
        "# split into train and valid\n",
        "train, valid = train_test_split(train, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2A1pqzcN_Gr"
      },
      "source": [
        "X_train = train[\"features\"].values.tolist()\n",
        "X_valid = valid[\"features\"].values.tolist()\n",
        "\n",
        "train_masks = train[\"masks\"].values.tolist()\n",
        "valid_masks = valid[\"masks\"].values.tolist()\n",
        "\n",
        "label_cols = ['Problem in recharge','Problem in reward/redeem points','Problem in registration/login/username/password','Problem with customer care service','Other complaints','Bad comments','Appreciation']\n",
        "Y_train = train[label_cols].values.tolist()\n",
        "Y_valid = valid[label_cols].values.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQUZkER-OCVE"
      },
      "source": [
        "# Create Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jChp-AsjOBrv"
      },
      "source": [
        "# create dataloaders\n",
        "# Convert all of our input ids and attention masks into \n",
        "# torch tensors, the required datatype for our model\n",
        "\n",
        "X_train = torch.tensor(X_train)\n",
        "X_valid = torch.tensor(X_valid)\n",
        "\n",
        "Y_train = torch.tensor(Y_train, dtype=torch.float32)\n",
        "Y_valid = torch.tensor(Y_valid, dtype=torch.float32)\n",
        "\n",
        "train_masks = torch.tensor(train_masks, dtype=torch.long)\n",
        "valid_masks = torch.tensor(valid_masks, dtype=torch.long)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMeaH6gbOHM1"
      },
      "source": [
        "# Batch size for training\n",
        "batch_size = 16\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader.\n",
        "train_data = TensorDataset(X_train, train_masks, Y_train)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data,\\\n",
        "                              sampler=train_sampler,\\\n",
        "                              batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(X_valid, valid_masks, Y_valid)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data,\\\n",
        "                                   sampler=validation_sampler,\\\n",
        "                                   batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCE_3AnLOPpI"
      },
      "source": [
        "def train(model, num_epochs,\\\n",
        "          optimizer,\\\n",
        "          train_dataloader, valid_dataloader,\\\n",
        "          model_save_path,\\\n",
        "          train_loss_set=[], valid_loss_set = [],\\\n",
        "          lowest_eval_loss=None, start_epoch=0,\\\n",
        "          device=\"cpu\"\n",
        "          ):\n",
        "  \"\"\"\n",
        "  Train the model and save the model with the lowest validation loss\n",
        "  \"\"\"\n",
        "\n",
        "  model.to(device)\n",
        "\n",
        "  # trange is a tqdm wrapper around the normal python range\n",
        "  for i in trange(num_epochs, desc=\"Epoch\"):\n",
        "    # if continue training from saved model\n",
        "    actual_epoch = start_epoch + i\n",
        "\n",
        "    # Training\n",
        "\n",
        "    # Set our model to training mode (as opposed to evaluation mode)\n",
        "    model.train()\n",
        "\n",
        "    # Tracking variables\n",
        "    tr_loss = 0\n",
        "    num_train_samples = 0\n",
        "\n",
        "    # Train the data for one epoch\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "      # Add batch to GPU\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      # Unpack the inputs from our dataloader\n",
        "      b_input_ids, b_input_mask, b_labels = batch\n",
        "      # Clear out the gradients (by default they accumulate)\n",
        "      optimizer.zero_grad()\n",
        "      # Forward pass\n",
        "      loss = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
        "      # store train loss\n",
        "      tr_loss += loss.item()\n",
        "      num_train_samples += b_labels.size(0)\n",
        "      # Backward pass\n",
        "      loss.backward()\n",
        "      # Update parameters and take a step using the computed gradient\n",
        "      optimizer.step()\n",
        "      #scheduler.step()\n",
        "\n",
        "    # Update tracking variables\n",
        "    epoch_train_loss = tr_loss/num_train_samples\n",
        "    train_loss_set.append(epoch_train_loss)\n",
        "\n",
        "    print(\"Train loss: {}\".format(epoch_train_loss))\n",
        "\n",
        "    # Validation\n",
        "\n",
        "    # Put model in evaluation mode to evaluate loss on the validation set\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss = 0\n",
        "    num_eval_samples = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in valid_dataloader:\n",
        "      # Add batch to GPU\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      # Unpack the inputs from our dataloader\n",
        "      b_input_ids, b_input_mask, b_labels = batch\n",
        "      # Telling the model not to compute or store gradients,\n",
        "      # saving memory and speeding up validation\n",
        "      with torch.no_grad():\n",
        "        # Forward pass, calculate validation loss\n",
        "        loss = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
        "        # store valid loss\n",
        "        eval_loss += loss.item()\n",
        "        num_eval_samples += b_labels.size(0)\n",
        "\n",
        "    epoch_eval_loss = eval_loss/num_eval_samples\n",
        "    valid_loss_set.append(epoch_eval_loss)\n",
        "\n",
        "    print(\"Valid loss: {}\".format(epoch_eval_loss))\n",
        "\n",
        "    if lowest_eval_loss == None:\n",
        "      lowest_eval_loss = epoch_eval_loss\n",
        "      # save model\n",
        "      save_model(model, model_save_path, actual_epoch,\\\n",
        "                 lowest_eval_loss, train_loss_set, valid_loss_set)\n",
        "    else:\n",
        "      if epoch_eval_loss < lowest_eval_loss:\n",
        "        lowest_eval_loss = epoch_eval_loss\n",
        "        # save model\n",
        "        save_model(model, model_save_path, actual_epoch,\\\n",
        "                   lowest_eval_loss, train_loss_set, valid_loss_set)\n",
        "    print(\"\\n\")\n",
        "\n",
        "  return model, train_loss_set, valid_loss_set\n",
        "\n",
        "\n",
        "def save_model(model, save_path, epochs, lowest_eval_loss, train_loss_hist, valid_loss_hist):\n",
        "  \"\"\"\n",
        "  Save the model to the path directory provided\n",
        "  \"\"\"\n",
        "  model_to_save = model.module if hasattr(model, 'module') else model\n",
        "  checkpoint = {'epochs': epochs, \\\n",
        "                'lowest_eval_loss': lowest_eval_loss,\\\n",
        "                'state_dict': model_to_save.state_dict(),\\\n",
        "                'train_loss_hist': train_loss_hist,\\\n",
        "                'valid_loss_hist': valid_loss_hist\n",
        "               }\n",
        "  torch.save(checkpoint, save_path)\n",
        "  print(\"Saving model at epoch {} with validation loss of {}\".format(epochs,\\\n",
        "                                                                     lowest_eval_loss))\n",
        "  return\n",
        "  \n",
        "def load_model(save_path):\n",
        "  \"\"\"\n",
        "  Load the model from the path directory provided\n",
        "  \"\"\"\n",
        "  checkpoint = torch.load(save_path)\n",
        "  model_state_dict = checkpoint['state_dict']\n",
        "  model = XLNetForMultiLabelSequenceClassification(num_labels=model_state_dict[\"classifier.weight\"].size()[0])\n",
        "  model.load_state_dict(model_state_dict)\n",
        "\n",
        "  epochs = checkpoint[\"epochs\"]\n",
        "  lowest_eval_loss = checkpoint[\"lowest_eval_loss\"]\n",
        "  train_loss_hist = checkpoint[\"train_loss_hist\"]\n",
        "  valid_loss_hist = checkpoint[\"valid_loss_hist\"]\n",
        "  \n",
        "  return model, epochs, lowest_eval_loss, train_loss_hist, valid_loss_hist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoxSrbFDOUW0"
      },
      "source": [
        "# Train Model from Scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGMnhaIuUbXx"
      },
      "source": [
        "# train model from scratch\n",
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VMI7VWpOKj0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2e49c8c-471e-48c4-baf4-ce1af47a4da1"
      },
      "source": [
        "#config = XLNetConfig()\n",
        "        \n",
        "class XLNetForMultiLabelSequenceClassification(torch.nn.Module):\n",
        "  \n",
        "  def __init__(self, num_labels=2):\n",
        "    super(XLNetForMultiLabelSequenceClassification, self).__init__()\n",
        "    self.num_labels = num_labels\n",
        "    self.xlnet = XLNetModel.from_pretrained('xlnet-base-cased')\n",
        "    self.classifier = torch.nn.Linear(768, num_labels)\n",
        "\n",
        "    torch.nn.init.xavier_normal_(self.classifier.weight)\n",
        "\n",
        "  def forward(self, input_ids, token_type_ids=None,\\\n",
        "              attention_mask=None, labels=None):\n",
        "    # last hidden layer\n",
        "    last_hidden_state = self.xlnet(input_ids=input_ids,\\\n",
        "                                   attention_mask=attention_mask,\\\n",
        "                                   token_type_ids=token_type_ids)\n",
        "    # pool the outputs into a mean vector\n",
        "    mean_last_hidden_state = self.pool_hidden_state(last_hidden_state)\n",
        "    logits = self.classifier(mean_last_hidden_state)\n",
        "        \n",
        "    if labels is not None:\n",
        "      loss_fct = BCEWithLogitsLoss()\n",
        "      loss = loss_fct(logits.view(-1, self.num_labels),\\\n",
        "                      labels.view(-1, self.num_labels))\n",
        "      return loss\n",
        "    else:\n",
        "      return logits\n",
        "    \n",
        "  def freeze_xlnet_decoder(self):\n",
        "    \"\"\"\n",
        "    Freeze XLNet weight parameters. They will not be updated during training.\n",
        "    \"\"\"\n",
        "    for param in self.xlnet.parameters():\n",
        "      param.requires_grad = False\n",
        "    \n",
        "  def unfreeze_xlnet_decoder(self):\n",
        "    \"\"\"\n",
        "    Unfreeze XLNet weight parameters. They will be updated during training.\n",
        "    \"\"\"\n",
        "    for param in self.xlnet.parameters():\n",
        "      param.requires_grad = True\n",
        "    \n",
        "  def pool_hidden_state(self, last_hidden_state):\n",
        "    \"\"\"\n",
        "    Pool the output vectors into a single mean vector \n",
        "    \"\"\"\n",
        "    last_hidden_state = last_hidden_state[0]\n",
        "    mean_last_hidden_state = torch.mean(last_hidden_state, 1)\n",
        "    return mean_last_hidden_state\n",
        "    \n",
        "model = XLNetForMultiLabelSequenceClassification(num_labels=len(Y_train[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.weight', 'lm_loss.bias']\n",
            "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QuSJxanOMRy"
      },
      "source": [
        "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01, correct_bias=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTMnS064cWu4",
        "outputId": "ef90f41a-1eee-4db8-894f-3c2efaf6a402"
      },
      "source": [
        "# import drive in colab to get a model save path\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxCN5nLvOO2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7b99b5a-e891-460c-c1c9-58ea096d1feb"
      },
      "source": [
        "# training..\n",
        "num_epochs=3\n",
        "\n",
        "model_save_name = 'classifier_model1.pt'\n",
        "model_save_path = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
        "model, train_loss_set, valid_loss_set = train(model=model,\\\n",
        "                                              num_epochs=num_epochs,\\\n",
        "                                              optimizer=optimizer,\\\n",
        "                                              train_dataloader=train_dataloader,\\\n",
        "                                              valid_dataloader=validation_dataloader,\\\n",
        "                                              model_save_path=model_save_path,\\\n",
        "                                              device=\"cuda\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/3 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.0054599517184351146\n",
            "Valid loss: 0.003236652824167415\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  33%|      | 1/3 [15:20<30:41, 920.52s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saving model at epoch 0 with validation loss of 0.003236652824167415\n",
            "\n",
            "\n",
            "Train loss: 0.0022549303461320367\n",
            "Valid loss: 0.0028260064589883736\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  67%|   | 2/3 [30:38<15:19, 919.73s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saving model at epoch 1 with validation loss of 0.0028260064589883736\n",
            "\n",
            "\n",
            "Train loss: 0.0014024759660813371\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 100%|| 3/3 [45:54<00:00, 918.25s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Valid loss: 0.003301545290242618\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHt9MdUoOaLl"
      },
      "source": [
        "# Train Model From Previous Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzZEnoI3Ob2u"
      },
      "source": [
        "# train model from previous checkpoint\n",
        "model_save_name = 'classifier_model1.pt'\n",
        "model_save_path = F\"/content/gdrive/My Drive/{model_save_name}\"\n",
        "model, start_epoch, lowest_eval_loss, train_loss_hist, valid_loss_hist = load_model(model_save_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrTdby8Uaqqb"
      },
      "source": [
        "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01, correct_bias=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiwYWrPsREQ-"
      },
      "source": [
        "num_epochs=3\n",
        "model, train_loss_set, valid_loss_set = train(model=model,\\\n",
        "                                              num_epochs=num_epochs,\\\n",
        "                                              optimizer=optimizer,\\\n",
        "                                              train_dataloader=train_dataloader,\\\n",
        "                                              valid_dataloader=validation_dataloader,\\\n",
        "                                              model_save_path=model_save_path,\\\n",
        "                                              train_loss_set=train_loss_hist,\\\n",
        "                                              valid_loss_set=valid_loss_hist,\\\n",
        "                                              lowest_eval_loss=lowest_eval_loss,\\\n",
        "                                              start_epoch=start_epoch,\\\n",
        "                                              device=\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hfFhwOrRj4t"
      },
      "source": [
        "# save the model\n",
        "torch. save(model. state_dict(), model_save_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12PYfqX3QrE-"
      },
      "source": [
        "# Get Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey9FMYJxQqGs"
      },
      "source": [
        "# get predictions\n",
        "def generate_predictions(model, df, num_labels, device=\"cpu\", batch_size=32):\n",
        "  num_iter = math.ceil(df.shape[0]/batch_size)\n",
        "  \n",
        "  pred_probs = np.array([]).reshape(0, num_labels)\n",
        "  \n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "  \n",
        "  for i in range(num_iter):\n",
        "    df_subset = df.iloc[i*batch_size:(i+1)*batch_size,:]\n",
        "    X = df_subset[\"features\"].values.tolist()\n",
        "    masks = df_subset[\"masks\"].values.tolist()\n",
        "    X = torch.tensor(X)\n",
        "    masks = torch.tensor(masks, dtype=torch.long)\n",
        "    X = X.to(device)\n",
        "    masks = masks.to(device)\n",
        "    with torch.no_grad():\n",
        "      logits = model(input_ids=X, attention_mask=masks)\n",
        "      logits = logits.sigmoid().detach().cpu().numpy()\n",
        "      pred_probs = np.vstack([pred_probs, logits])\n",
        "  \n",
        "  return pred_probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo0YyAH6XGTh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a39fb3c8-b3b0-4ba1-95b6-faace04e2457"
      },
      "source": [
        "num_labels = len(label_cols)\n",
        "pred_probs = generate_predictions(model, test, num_labels, device=\"cuda\", batch_size=32)\n",
        "pred_probs = np.round(pred_probs, 3)\n",
        "# pred_probs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.26418785e-07, 7.21927762e-08, 5.00244113e-08, ...,\n",
              "        4.55935492e-07, 7.14609314e-08, 1.00000000e+00],\n",
              "       [3.10080992e-07, 6.26785166e-08, 5.39943521e-08, ...,\n",
              "        3.66178853e-07, 5.96945142e-08, 1.00000000e+00],\n",
              "       [5.12417091e-06, 8.35645210e-07, 1.46626360e-06, ...,\n",
              "        6.24060294e-06, 9.99872923e-01, 8.27477925e-05],\n",
              "       ...,\n",
              "       [1.15612900e-04, 8.55474151e-04, 1.63673230e-05, ...,\n",
              "        1.95052169e-04, 1.19782962e-05, 9.99762237e-01],\n",
              "       [1.29337241e-06, 5.01019429e-07, 1.80744493e-07, ...,\n",
              "        1.65683559e-06, 2.84675764e-07, 9.99999762e-01],\n",
              "       [2.73788032e-07, 6.32528128e-08, 4.51179254e-08, ...,\n",
              "        3.32330586e-07, 5.56356845e-08, 1.00000000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVAWKam2ado5"
      },
      "source": [
        "label_cols = ['Problem in recharge','Problem in reward/redeem points','Problem in registration/login/username/password','Problem with customer care service','Other complaints','Bad comments','Appreciation']\n",
        "\n",
        "test['Problem in recharge'] = pred_probs[:,0]\n",
        "test['Problem in reward/redeem points'] = pred_probs[:,1]\n",
        "test['Problem in registration/login/username/password'] = pred_probs[:,2]\n",
        "test['Problem with customer care service'] = pred_probs[:,3]\n",
        "test['Other complaints'] = pred_probs[:,4]\n",
        "test['Bad comments'] = pred_probs[:,5]\n",
        "test['Appreciation'] = pred_probs[:,6]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_l6LVlX_R9J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b76fba0b-2bed-40a1-9a10-8a23ffb74522"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>features</th>\n",
              "      <th>masks</th>\n",
              "      <th>Problem in recharge</th>\n",
              "      <th>Problem in reward/redeem points</th>\n",
              "      <th>Problem in registration/login/username/password</th>\n",
              "      <th>Problem with customer care service</th>\n",
              "      <th>Other complaints</th>\n",
              "      <th>Bad comments</th>\n",
              "      <th>Appreciation</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reviewId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>gp:AOqpTOGTADrOKHFXYgD5jwLGK1Ult0gcnjTCj3fqrKk4AEjJiPK90jg-o56Vf6X_Mtfbcibv6dEw3b5IqXR5mz0</th>\n",
              "      <td>good boy</td>\n",
              "      <td>[195, 2001, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>3.264188e-07</td>\n",
              "      <td>7.219278e-08</td>\n",
              "      <td>5.002441e-08</td>\n",
              "      <td>4.082840e-09</td>\n",
              "      <td>4.559355e-07</td>\n",
              "      <td>7.146093e-08</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gp:AOqpTOHG20z1AXXSPa5cRQQXNS3Mri57rOo9JNu0MZBZxnx8wgNl6oecPTvUEDZBJ1ix3ovWeYvsMgNUlNfdMJc</th>\n",
              "      <td>very nice</td>\n",
              "      <td>[172, 2101, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>3.100810e-07</td>\n",
              "      <td>6.267852e-08</td>\n",
              "      <td>5.399435e-08</td>\n",
              "      <td>4.083798e-09</td>\n",
              "      <td>3.661789e-07</td>\n",
              "      <td>5.969451e-08</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gp:AOqpTOEjMUAO5sa_j77QG0hp75avoD2FwOjevIlNWcXhLDyl6RZHpKyuO15V_kambTEUfczaPvSeQKTdYwfwVNI</th>\n",
              "      <td>bad app</td>\n",
              "      <td>[948, 5523, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>5.124171e-06</td>\n",
              "      <td>8.356452e-07</td>\n",
              "      <td>1.466264e-06</td>\n",
              "      <td>1.589592e-07</td>\n",
              "      <td>6.240603e-06</td>\n",
              "      <td>9.998729e-01</td>\n",
              "      <td>0.000083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gp:AOqpTOHxMcsJGLebsXniRuZk71y546Y-tCV0ME-gaZby9COr_vTk1c6Axe-T2jeejxwKsEaAHbbs7onwe3EQLPU</th>\n",
              "      <td>worst app</td>\n",
              "      <td>[2598, 5523, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>3.317411e-06</td>\n",
              "      <td>1.430770e-06</td>\n",
              "      <td>1.063038e-06</td>\n",
              "      <td>5.784522e-08</td>\n",
              "      <td>1.083658e-06</td>\n",
              "      <td>9.999573e-01</td>\n",
              "      <td>0.000028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gp:AOqpTOFGo_lltI1X7gImeKrUe7tnKJT0Nst6IIujSWrg9exW6eF5BA-b50g5XRXnVJBlbuyTSNhoOyonPZ-4Yzo</th>\n",
              "      <td>i have successfully registered but when i try ...</td>\n",
              "      <td>[17, 150, 47, 3918, 2815, 57, 90, 17, 150, 714...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
              "      <td>1.100581e-03</td>\n",
              "      <td>9.970652e-01</td>\n",
              "      <td>9.960038e-01</td>\n",
              "      <td>3.026004e-04</td>\n",
              "      <td>8.967006e-01</td>\n",
              "      <td>1.224051e-04</td>\n",
              "      <td>0.000364</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                              content  ... Appreciation\n",
              "reviewId                                                                                               ...             \n",
              "gp:AOqpTOGTADrOKHFXYgD5jwLGK1Ult0gcnjTCj3fqrKk4...                                           good boy  ...     1.000000\n",
              "gp:AOqpTOHG20z1AXXSPa5cRQQXNS3Mri57rOo9JNu0MZBZ...                                          very nice  ...     1.000000\n",
              "gp:AOqpTOEjMUAO5sa_j77QG0hp75avoD2FwOjevIlNWcXh...                                            bad app  ...     0.000083\n",
              "gp:AOqpTOHxMcsJGLebsXniRuZk71y546Y-tCV0ME-gaZby...                                          worst app  ...     0.000028\n",
              "gp:AOqpTOFGo_lltI1X7gImeKrUe7tnKJT0Nst6IIujSWrg...  i have successfully registered but when i try ...  ...     0.000364\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqrwRwxFGOvK"
      },
      "source": [
        "# test.to_csv('xlnet_classifier.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AADartP_DxPg"
      },
      "source": [
        "# Get results for a single comment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfLp_WDgGvsl"
      },
      "source": [
        "comment = \"recharge was bad and the customer care did not respond and the app was not working\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hx_ENYIS56vJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d1ad969-6056-4db6-a7f4-fca9a0d69dff"
      },
      "source": [
        "data = [[comment]]\n",
        "df1 = pd.DataFrame(data, columns = ['content'])\n",
        "df1_text_list = df1[\"content\"].values\n",
        "df1_input_ids = tokenize_inputs(df1_text_list, tokenizer, num_embeddings=250)\n",
        "df1_attention_masks = create_attn_masks(df1_input_ids)\n",
        "df1[\"features\"] = df1_input_ids.tolist()\n",
        "df1[\"masks\"] = df1_attention_masks\n",
        "num_labels = len(label_cols)\n",
        "pred_probs = generate_predictions(model, df1, num_labels, device=\"cuda\", batch_size=1)\n",
        "pred_probs = np.round(pred_probs, 3)\n",
        "probsList = [ item for elem in pred_probs for item in elem]\n",
        "probsList        "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.999, 0.001, 0.0, 1.0, 0.932, 0.0, 0.001]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcsFqGgW6VYZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24768065-fc56-490d-e5bb-fa4098e28a4e"
      },
      "source": [
        "THRESHOLD = 0.5\n",
        "if probsList[0] < THRESHOLD and probsList[1] < THRESHOLD and probsList[2] < THRESHOLD and probsList[\n",
        "    3] < THRESHOLD and probsList[4] < THRESHOLD and probsList[5] < THRESHOLD and probsList[6] < THRESHOLD:\n",
        "    st.subheader(\"Your text does not belong to any category!\")\n",
        "else:\n",
        "    for label, prediction in zip(label_cols, probsList):\n",
        "        if prediction < THRESHOLD:\n",
        "            continue\n",
        "        print(f\"{label}: {prediction}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Problem in recharge: 0.999\n",
            "Problem with customer care service: 1.0\n",
            "Other complaints: 0.932\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
